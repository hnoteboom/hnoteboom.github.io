[
  {
    "objectID": "articles.html",
    "href": "articles.html",
    "title": "Articles",
    "section": "",
    "text": "Here’s an article I wrote for the travel magazine, Catalyst Planet about my travels in Vietnam!\n\n\n\nPreview of Ha Giang article"
  },
  {
    "objectID": "articles.html#catalyst-planet-feature",
    "href": "articles.html#catalyst-planet-feature",
    "title": "Articles",
    "section": "",
    "text": "Here’s an article I wrote for the travel magazine, Catalyst Planet about my travels in Vietnam!\n\n\n\nPreview of Ha Giang article"
  },
  {
    "objectID": "data-viz/bechdel-test.html",
    "href": "data-viz/bechdel-test.html",
    "title": "Bechdel Test",
    "section": "",
    "text": "The Bechdel Test is a test developed by Liz Wallace and Alison Bechdel to measure the representation of women in media, especially film. To pass the test, the film must have two named female characters who have a conversation about something other than a man.\nThe data used comes from a tidy Tuesday dataset with IMDB ratings and Bechdel test results for movies from 1970-2013.\nThe figure above shows the average IMDB rating for movies that pass and fail the Bechdel Test. The graph shows slightly higher ratings for movies that Fail the test rather than those that Pass. Movies that fail have an average rating of 6.89 and movies that pass have an average rating of 6.6."
  },
  {
    "objectID": "data-viz/bechdel-test.html#references",
    "href": "data-viz/bechdel-test.html#references",
    "title": "Bechdel Test",
    "section": "References:",
    "text": "References:\nOriginal Source: https://bechdeltest.com/\nTidyTuesday Source: https://github.com/rfordatascience/tidytuesday/blob/main/data/2021/2021-03-09/readme.md"
  },
  {
    "objectID": "data-viz/national-parks.html",
    "href": "data-viz/national-parks.html",
    "title": "National Park Species",
    "section": "",
    "text": "This data comes from the National Parks Service and has information on every species present in national parks across the country. This data set includes data from the 15 most popular parks. The data set contains information on each species’ taxonomy and occurrences of the species in the park.\nThe figure above shows the number of individual species in different species categories present in Rocky Mountain National Park."
  },
  {
    "objectID": "data-viz/national-parks.html#references",
    "href": "data-viz/national-parks.html#references",
    "title": "National Park Species",
    "section": "References:",
    "text": "References:\nOriginal Source: https://irma.nps.gov/NPSpecies/Search/SpeciesList\nTidyTuesday Source: https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-10-08/readme.md"
  },
  {
    "objectID": "data-viz/simulation.html",
    "href": "data-viz/simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Simulation\n\n\nR packages and Data Loading\nlibrary(tidyverse)\n\nmeasles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-25/measles.csv')\n\ntuesdata &lt;- tidytuesdayR::tt_load('2020-02-25')\ntuesdata &lt;- tidytuesdayR::tt_load(2020, week = 9)\n\nmeasles &lt;- tuesdata$measles\n\n\nFor this project I have conducted a permutation test on vaccine rates among different types of schools. The dataset I am using is compiled of 46,412 schools across 32 US States for the 2017-2018 or 2018-2019 (depending on state) school year. This data looks specifically at the vaccine for Measles, Mumps, and Rubella (mmr). The vaccine is federally mandated in public schools but some children are exempt due to medical or religious reasons and there have been other ways that schools can avoid vaccine mandates. I wanted to see if the type of school influenced vaccine rates, the types of schools in this dataset are:\n\nPublic\nPrivate\nCharter\nKindergarten\nBOCES\n\nPublic schools are those funded by the government. Private schools are privately owned and not government funded. Charter schools are also publicly funded but operate outside of the established state school system. Kindergarten are schools for only elementary school students. BOCES is a special program in New York that serves as an extension of publicly funded schools. Despite being publicly funded, charter schools have more flexibility than regular public schools when it comes to curriculum and operations. I wanted to see if this flexibility made a difference in vaccination rates. The population to which I am generalizing is all schools in the US in the years between 2017 and 2019.\nMy research question is:\nIn the population, do public schools have higher vaccination rates than charter schools on average?\n\\(H_0\\) = \\(\\mu_{\\text{public}} = \\mu_{\\text{charter}}\\)\n\\(H_A\\) = \\(\\mu_{\\text{public}} &gt; \\mu_{\\text{charter}}\\)\nThe graph below shows the average vaccination rate for Public and Charter Schools.\n\n\nData Filtering and Box Plot Creation\nc_p_measles &lt;- measles |&gt; \n  select(type, mmr) |&gt; \n  filter(type == \"Charter\" | type == \"Public\") |&gt;\n  filter(mmr &gt; 1)  #Filtering out because MMR is an optional variable, default is -1 or 1. \n\nggplot(c_p_measles, aes(x = type, y = mmr, fill = type)) +\n  geom_boxplot() +\n  labs(\n    x = \"School Type\", \n    y = \"MMR Vaccination Rate\", \n    title = \"Distribution of MMR Vaccination Rates by School Type\"\n  )\n\n\n\n\n\n\n\n\n\nThe box plot above shows MMR vaccine rates for Public and Charter Schools. Most public schools have consistently high MMR rates, which can be seen in the high median, but there’s a sizable minority with alarmingly low rates, making them statistical outliers. Charter schools show more variation in vaccination rates. The variation is more evenly spread, with fewer extreme low performers than public schools.\nI found that the difference between the average vaccine rates for Public and Charter schools to be 8.211511. To test if this is outside the null distribution, I conducted a permutation test in which I scrambled the mmr rates. The histogram of the null distribution can be seen below and the red line marks the observed difference between vaccination rates.\n\n\nPermutation Test\nperm_test &lt;- function(rep, data) {\n  data |&gt;\n    select(type, mmr) |&gt; \n    filter(type == \"Public\" | type == \"Charter\") |&gt; \n    filter(mmr &gt; 1) |&gt;\n    mutate(mmr_perm = sample(mmr, replace = FALSE)) |&gt;\n    group_by(type) |&gt;\n    summarize(ave_rate = mean(mmr), \n              ave_rate_perm = mean(mmr_perm)) |&gt; \n    summarize(ave_diff = diff(ave_rate), \n              ave_diff_perm = diff(ave_rate_perm), \n              rep = rep)}\n\nset.seed(44)\nperm_stats &lt;- \n  map(c(1:500), perm_test, data = measles) |&gt; \n  list_rbind() \n\n\n\n\nHistogram Creation\nperm_stats |&gt; \n  ggplot(aes(x = ave_diff_perm)) + \n  geom_histogram(bins = 50) + \n  geom_vline(aes(xintercept = ave_diff), color = \"red\") + \n  labs(\n    title = \"Null distribution\", \n    x = \"Average difference\"\n  )\n\n\n\n\n\n\n\n\n\nHistogram Creation\nperm_stats |&gt; \n  summarize(p_val_ave = mean(ave_diff_perm &gt; ave_diff))\n\n\n# A tibble: 1 × 1\n  p_val_ave\n      &lt;dbl&gt;\n1         0\n\n\nI found that the p-value is 0 which means the result is statistically significant as p-value &lt; 0.05. Therefore we can accept the alternative hypothesis and say that on average, public schools in the US have higher vaccination rates than charter schools.\n\n\nReferences\nTidy Tuesday source: https://github.com/rfordatascience/tidytuesday/tree/main/data/2020/2020-02-25\nOriginal source: The Wall Street Journal. (2019). Measles vaccination and exemption data. GitHub. https://github.com/WSJ/measles-data"
  },
  {
    "objectID": "data-viz/Project_5.html",
    "href": "data-viz/Project_5.html",
    "title": "Project_5",
    "section": "",
    "text": "For this analysis I decided to look at a few different questions. First, I wanted to see if the number of police stops labeled as Vehicular in the state of California were changing over time. I was also interested to see if the rate of stops that resulted in arrests was also changing. I next wanted to see if there was any difference in the number of stops depending on the day of the month, I picked to look at data from San Francisco as it had data that spanned almost 10 years. Lastly, I wanted to see the racial breakdown of stops in Florida to see if there were differences in the rates of stops for different races. All of the data used in this analysis comes from the Stanford Open Policing Project.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(DBI)\nlibrary(scales)\n\n\n\nSELECT \n  YEAR(date) AS year, \n  MIN(date) as start_date, \n  MAX(date) as end_date\nFROM ca_statewide_2023_01_26\nGROUP BY year\n\n\n8 records\n\n\nyear\nstart_date\nend_date\n\n\n\n\n2009\n2009-07-01\n2009-12-30\n\n\n2010\n2010-01-01\n2010-12-31\n\n\n2011\n2011-01-01\n2011-12-31\n\n\n2012\n2012-01-01\n2012-12-31\n\n\n2013\n2013-01-01\n2013-12-31\n\n\n2014\n2014-01-01\n2014-12-31\n\n\n2015\n2015-01-01\n2015-12-31\n\n\n2016\n2016-01-01\n2016-06-30\n\n\n\n\n\nI used the table above to see the dates that the data spanned. Since the start date for 2009 was halfway through the year and the end date for 2016 was also halfway through the year, I decided to leave these years out of my data analysis.\n\nSELECT \n  YEAR(date) AS year, \n  COUNT(*) AS count, \n  AVG(arrest_made) as arrested\nFROM ca_statewide_2023_01_26\nWHERE type = \"vehicular\"\nGROUP BY year\nHAVING \n  year != 2009 AND year != 2016\nORDER BY year DESC\n\n\narrests_ca_statewide\n\n  year   count   arrested\n1 2015 4037737 0.03658444\n2 2014 4149966 0.03673524\n3 2013 4428744 0.03639640\n4 2012 4602338 0.03838172\n5 2011 5061034 0.03699215\n6 2010 5075533 0.03781909\n\n\nThe table above shows the number of vehicular traffic stops in the state of California for the years between 2010 and 2015. The arrested column represents the percentage of vehicular stops that resulted in arrest. There is consistently around 3% of stops resulting in arrests.\n\narrests_ca_statewide &lt;- arrests_ca_statewide |&gt; \n  mutate(year = as.character(year), count = as.numeric(count)) \n\nggplot(arrests_ca_statewide, aes(x = year, y = count, fill = year)) + \n  geom_col()+ \n  scale_y_continuous(\n    labels = label_number(scale = 1e-6, suffix = \"M\", accuracy = 0.1)\n  ) +\n  labs(\n    x = \"Year\", \n    y = \"Count in millions\", \n    title = \"Number of Vehicular Stops in California\"\n  )\n\n\n\n\n\n\n\n\nThe graph above shows the number of police stops recorded as vehicular in the state of California across the years from 2010 to 2015. The graph shows a steady decline in the number of stops each year from 2011 to 2015, with stops decreasing from around 5 million in 2011 to 4 million in 2015. This graph combined with the table above shows that while the number of stops is decreasing, the proportion of stops that result in arrest remains relatively the same, around 3%.\n\nSELECT DAY(date) AS day, COUNT(*) AS count\nFROM ca_san_francisco_2020_04_01\nWHERE type = \"vehicular\"\nGROUP BY day\nLIMIT 0, 31;\n\n\ndate_count_sf |&gt; \n  mutate(count = as.numeric(count))|&gt; \n  ggplot(aes(x = day, y = count))+ \n  geom_col() +\n  labs(\n    x = \"Day of the month\", \n    y = \"Number of stops\", \n    title = \"Number of Police Stops on Different Days of the Month in San Fransisco\"\n  )\n\n\n\n\n\n\n\n\nThe graph above shows police stops for different days of the month in San Francisco. The data spans all stops from 2007 to 2016. There is a common myth that you are more likely to be pulled over toward the end of the month because police departments need to meet a monthly quota. This data shows no real difference in stop rates between different days of the month. There is some variation among the days which is to be expected. The last days of the month, the 29th, 30th and 31st have the lowest rates with the 31st having significantly less than any other day. This is because not every month has 31 days (or even 29 in the case of February), so naturally there will be less stops on those days of the month.\n\n\nSELECT \n  subject_race, \n  COUNT(*) AS count, \n  COUNT(*) * 100.0 / (SELECT COUNT(*) FROM fl_statewide_2020_04_01 WHERE subject_race IS NOT NULL) AS percent\nFROM fl_statewide_2020_04_01 \nGROUP BY subject_race\nHAVING subject_race IS NOT NULL \n\n\n6 records\n\n\nsubject_race\ncount\npercent\n\n\n\n\nasian/pacific islander\n93421\n1.28049\n\n\nblack\n1409006\n19.31276\n\n\nhispanic\n1502816\n20.59859\n\n\nother\n201920\n2.76765\n\n\nunknown\n250\n0.00343\n\n\nwhite\n4088311\n56.03708\n\n\n\n\n\nThe table above shows the race of individuals involved in police stops in Florida from 2010 to 2018. Over 56% of all subjects were white, and around 20% were Hispanic and Black. No real conclusions can be drawn from this data for multiple reasons. Officers often cannot ask people their race but must report it leading to officers making assumptions about subjects race. Biracial people might be inaccurately represented in the data and without knowing the racial percentage break down of drivers in Florida, it is impossible to make any general claims about whether these rates are proportional to overall population or not."
  },
  {
    "objectID": "data-viz/Project_5.html#sql-data-analysis",
    "href": "data-viz/Project_5.html#sql-data-analysis",
    "title": "Project_5",
    "section": "",
    "text": "For this analysis I decided to look at a few different questions. First, I wanted to see if the number of police stops labeled as Vehicular in the state of California were changing over time. I was also interested to see if the rate of stops that resulted in arrests was also changing. I next wanted to see if there was any difference in the number of stops depending on the day of the month, I picked to look at data from San Francisco as it had data that spanned almost 10 years. Lastly, I wanted to see the racial breakdown of stops in Florida to see if there were differences in the rates of stops for different races. All of the data used in this analysis comes from the Stanford Open Policing Project.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(DBI)\nlibrary(scales)\n\n\n\nSELECT \n  YEAR(date) AS year, \n  MIN(date) as start_date, \n  MAX(date) as end_date\nFROM ca_statewide_2023_01_26\nGROUP BY year\n\n\n8 records\n\n\nyear\nstart_date\nend_date\n\n\n\n\n2009\n2009-07-01\n2009-12-30\n\n\n2010\n2010-01-01\n2010-12-31\n\n\n2011\n2011-01-01\n2011-12-31\n\n\n2012\n2012-01-01\n2012-12-31\n\n\n2013\n2013-01-01\n2013-12-31\n\n\n2014\n2014-01-01\n2014-12-31\n\n\n2015\n2015-01-01\n2015-12-31\n\n\n2016\n2016-01-01\n2016-06-30\n\n\n\n\n\nI used the table above to see the dates that the data spanned. Since the start date for 2009 was halfway through the year and the end date for 2016 was also halfway through the year, I decided to leave these years out of my data analysis.\n\nSELECT \n  YEAR(date) AS year, \n  COUNT(*) AS count, \n  AVG(arrest_made) as arrested\nFROM ca_statewide_2023_01_26\nWHERE type = \"vehicular\"\nGROUP BY year\nHAVING \n  year != 2009 AND year != 2016\nORDER BY year DESC\n\n\narrests_ca_statewide\n\n  year   count   arrested\n1 2015 4037737 0.03658444\n2 2014 4149966 0.03673524\n3 2013 4428744 0.03639640\n4 2012 4602338 0.03838172\n5 2011 5061034 0.03699215\n6 2010 5075533 0.03781909\n\n\nThe table above shows the number of vehicular traffic stops in the state of California for the years between 2010 and 2015. The arrested column represents the percentage of vehicular stops that resulted in arrest. There is consistently around 3% of stops resulting in arrests.\n\narrests_ca_statewide &lt;- arrests_ca_statewide |&gt; \n  mutate(year = as.character(year), count = as.numeric(count)) \n\nggplot(arrests_ca_statewide, aes(x = year, y = count, fill = year)) + \n  geom_col()+ \n  scale_y_continuous(\n    labels = label_number(scale = 1e-6, suffix = \"M\", accuracy = 0.1)\n  ) +\n  labs(\n    x = \"Year\", \n    y = \"Count in millions\", \n    title = \"Number of Vehicular Stops in California\"\n  )\n\n\n\n\n\n\n\n\nThe graph above shows the number of police stops recorded as vehicular in the state of California across the years from 2010 to 2015. The graph shows a steady decline in the number of stops each year from 2011 to 2015, with stops decreasing from around 5 million in 2011 to 4 million in 2015. This graph combined with the table above shows that while the number of stops is decreasing, the proportion of stops that result in arrest remains relatively the same, around 3%.\n\nSELECT DAY(date) AS day, COUNT(*) AS count\nFROM ca_san_francisco_2020_04_01\nWHERE type = \"vehicular\"\nGROUP BY day\nLIMIT 0, 31;\n\n\ndate_count_sf |&gt; \n  mutate(count = as.numeric(count))|&gt; \n  ggplot(aes(x = day, y = count))+ \n  geom_col() +\n  labs(\n    x = \"Day of the month\", \n    y = \"Number of stops\", \n    title = \"Number of Police Stops on Different Days of the Month in San Fransisco\"\n  )\n\n\n\n\n\n\n\n\nThe graph above shows police stops for different days of the month in San Francisco. The data spans all stops from 2007 to 2016. There is a common myth that you are more likely to be pulled over toward the end of the month because police departments need to meet a monthly quota. This data shows no real difference in stop rates between different days of the month. There is some variation among the days which is to be expected. The last days of the month, the 29th, 30th and 31st have the lowest rates with the 31st having significantly less than any other day. This is because not every month has 31 days (or even 29 in the case of February), so naturally there will be less stops on those days of the month.\n\n\nSELECT \n  subject_race, \n  COUNT(*) AS count, \n  COUNT(*) * 100.0 / (SELECT COUNT(*) FROM fl_statewide_2020_04_01 WHERE subject_race IS NOT NULL) AS percent\nFROM fl_statewide_2020_04_01 \nGROUP BY subject_race\nHAVING subject_race IS NOT NULL \n\n\n6 records\n\n\nsubject_race\ncount\npercent\n\n\n\n\nasian/pacific islander\n93421\n1.28049\n\n\nblack\n1409006\n19.31276\n\n\nhispanic\n1502816\n20.59859\n\n\nother\n201920\n2.76765\n\n\nunknown\n250\n0.00343\n\n\nwhite\n4088311\n56.03708\n\n\n\n\n\nThe table above shows the race of individuals involved in police stops in Florida from 2010 to 2018. Over 56% of all subjects were white, and around 20% were Hispanic and Black. No real conclusions can be drawn from this data for multiple reasons. Officers often cannot ask people their race but must report it leading to officers making assumptions about subjects race. Biracial people might be inaccurately represented in the data and without knowing the racial percentage break down of drivers in Florida, it is impossible to make any general claims about whether these rates are proportional to overall population or not."
  },
  {
    "objectID": "data-viz/Project_5.html#conclusion",
    "href": "data-viz/Project_5.html#conclusion",
    "title": "Project_5",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, data from the Stanford Open Policing Project shows that between 2011 and 2015 the number of police stops consistently decreased in the state of California but the arrest rate remained the same. According to data from San Francisco there is no significant difference in police stops on different days of the month. And the majority of people stopped in Florida between 2010 and 2018 were reported to be white."
  },
  {
    "objectID": "data-viz/Project_5.html#references",
    "href": "data-viz/Project_5.html#references",
    "title": "Project_5",
    "section": "References",
    "text": "References\nPierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10.\n\ndbDisconnect(con_traffic)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harper Noteboom",
    "section": "",
    "text": "Hi there I’m Harper! I’m a student at Pomona College studying Computer Science and Data Science. Outside of my studies, I enjoy reading, hiking, and travel. Take a look around my website to learn more!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "data-viz/ethics.html",
    "href": "data-viz/ethics.html",
    "title": "Ethics in Data Science",
    "section": "",
    "text": "Case Study: Target’s pregnancy predicting algorithm\nTarget is a retail corporation and one of the nation’s biggest department store chains. They offer a wide variety of goods from groceries, to clothing, to baby products. In 2012, an article in the New York Times titled “How Companies Learn Your Secrets” by Charles Duhigg exposed the company’s “pregnancy predictor” algorithm. The algorithm, created by statistician Andrew Pole, uses customers’ shopping habits to predict if they are pregnant, with the goal of targeting advertising to increase sales and build customer loyalty. By predicting whether an individual is pregnant, Target can advertise baby products to them before the child is born and influence their shopping habits. This algorithm took data from customers, often without their knowledge or consent, and used it to benefit the company without the consumer knowing what was going on\n\n\nBackground\nAndrew Pole was hired by Target to use his insights into consumer habits to increase Target’s sales. He was tasked with identifying the moments in consumers’ lives where they are undergoing great changes and so their shopping habits were also susceptible to change. One such period was the time around the birth of a child. Target wanted to reach new parents before other brands could, which led them to want to know if their customers were pregnant, even if they didn’t want the brand to know.\nPole began by looking at baby shower registries, where pregnant people willingly disclosed their pregnancy. He observed how these people’s spending habits changed as they approached their due date. One of the trends he noticed was that many people began to buy lots of unscented lotion around the beginning of their second trimester and an increase in vitamins in their first trimester. Through all of this data, Pole developed a list of 25 products that allowed him to give each consumer a “pregnancy prediction” score, as well as an estimate of their due date. This would then allow Target to send the customer specialized ads for relevant products as they approached their due date. Target also used information about habit building to increase the variety of products that consumers would purchase.\nPole then applied this algorithm to every regular female shopper in the nation and produced a list of thousands of people who it found were most likely pregnant. While this is not illegal—Target says they comply with all federal and state laws—and it isn’t a case of leaked or stolen data, this story still spurs ethical questions related to data collection and use. Some of the ethical concerns that this raises are: Who benefits from the use of this data and who suffers? Should it be possible for brands to predict sensitive health information? What should they be able to do with this information?\n\n\nData Values and Principles Manifesto\nThe first item in the Data Values and Principles Manifesto states, “Use data to improve life for our users, customers, organizations, and communities.” This raises the question of whose life is really improved by this algorithm. Target might claim that the algorithm can actually be beneficial to pregnant people. By providing them with advertisements and coupons it makes it easier for customers to get the products they need and even save money.\nAs described in the New York Times article, new parents are often overwhelmed and they no longer want to shop at different stores for different items. By advertising the diversity of Target’s products, they made it easier for parents to get everything they need from one store.\nIn the article, “Target Knows You’re Pregnant; Is This What Customers Really Want,” Brian Cantor makes the argument that consumers like when ads are targeted toward their preferences and needs and that it makes shopping a better experience for them.\nHowever, I don’t think this is actually improving the lives of users. Advertising is one thing, but using data to predict sensitive information about someone under the guise of benefiting them is different. In reality, Target, as a corporation, benefits from this algorithm.\nAdditionally, while Target might claim that this information is purely for advertising purposes, when placed in the wrong hands, information about a person’s reproductive status can have detrimental effects on their life. In the book Predictive Analytics by Eric Siegel, he cites an online user who explained the scenario of a pregnant woman with a precarious job, struggling to get state disability—if this woman’s pregnancy was leaked, she could risk losing her benefits and her job.\nEspecially in a post-Roe v. Wade society, reproductive information is extremely sensitive and the pregnant person should have full control over who knows that information. While this data increases Target’s profits and could benefit customers, it also has the potential to harm many people.\n\n\nWhat was the consent structure?\nThe data being used came from baby registries, purchase history, and customer profiles. Customers making baby registries willingly provided their status and due date, and customers in the store technically agreed to Target knowing their purchase history. However, the “participants” whose data was being used were not aware of exactly the applications of their data.\nCustomers that have Target accounts or loyalty cards accept certain terms and conditions that are usually long and hard to understand. Technically, this is customers giving their consent to their data being used. Customers were not aware that their data would be used to create a predictive model that could reveal sensitive health information.\nThis creates the question of: Can you provide informed consent for applications that are not yet foreseen? Target customers could never have known what their data would be used for, and it is virtually impossible to ever give consent for future applications that are unknown. To some extent, that’s a risk we take in the digital age. However, I think that even if participants have given “consent,” companies should be prevented from manipulating that “consent” in ethically ambiguous ways.\n\n\nWere the data made publicly available?\nThe algorithm that Pole created and the data about individuals’ “pregnancy scores” has not become publicly available. In this case, it is crucial to the privacy, autonomy, and well-being of Target customers that this data remains non-public. However, it is important to keep in mind that “non-public” does not mean private. Target could be selling this data to other companies so it is impossible to know who actually has access to this data and what they are using it for. Additionally, there could be some benefit to making the algorithm or anonymous data public so that the data science community can check for bias and keep Target accountable for their actions.\n\n\nWho was measured? Are the representative of whom we want to generalize?\nOne thing that should be considered when discussing ethics in data is representation in the data and who we are generalizing to. In this case, the individuals measured were regular Target shoppers who used loyalty cards or credit cards. While this is not representative of the whole population and is likely skewed by demographics like income, age, and race, it may not be as big of a concern in this case. Target is applying their algorithm to other target shoppers in which case the data is representative of the populations we are generalizing to.\n\n\nConclusion\nIn conclusion, Targets “pregnancy predictor” raises many ethical questions surrounding data use and corporations use of data to predict sensitive health information about their customers. Working in the field of data science requires critical examination of our biases and consideration of ethical issues surrounding data.\n\n\nSources:\nDuhigg, Charles. “How Companies Learn Your Secrets.” The New York Times Magazine, 16 Feb. 2012, www.nytimes.com/2012/02/19/magazine/shopping-habits.html.\nCantor, Brian. “Target Knows You’re Pregnant; Is This What Customers Really Want?” Customer Contact Week Digital, www.customercontactweekdigital.com/customer-experience/articles/target-knows-you-re-pregnant-is-this-what-customer. Accessed 16 Apr. 2025.\nSiegel, Eric. Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die. Revised and Updated ed., Wiley, 2016."
  },
  {
    "objectID": "data-viz/text-analysis.html",
    "href": "data-viz/text-analysis.html",
    "title": "Full Text Analysis",
    "section": "",
    "text": "Dataset\nThe data I have chosen is about board games that were released between 1950 and 2016. The data comes from the site BoardGameGeek which is a website for board game enthusiasts that features reviews, forums, and board game data. The dataset has information about each games category, release date, description, average rating, and more.\n\n\nR Packages and Data Loading\nlibrary(tidyverse)\n\nboard_games &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2019/2019-03-12/board_games.csv\")\n\n\n\n\nAnalysis 1\nI first wanted to find out what the most common words in the titles of games were. I filtered out filler words like “the”, “and”, “to”, etc. The top ten most common words board game titles can be seen in the table below.\n\n\nTibble of Most Popular Words\nboard_games |&gt;\n  mutate(words = str_extract_all(name, \"\\\\b\\\\w+\\\\b\")) |&gt;  \n  unnest(words) |&gt;                                         \n  count(words, sort = TRUE) |&gt; \n  filter(!str_detect(words, \"^(?i)(the|of|to|game|s|in|and|a|for|at)$\"))|&gt;\n  head(10)\n\n\n# A tibble: 10 × 2\n   words        n\n   &lt;chr&gt;    &lt;int&gt;\n 1 War        270\n 2 Edition    215\n 3 Card       201\n 4 Battle     140\n 5 Star       125\n 6 Wars       118\n 7 edition    107\n 8 World      101\n 9 Dice        99\n10 Monopoly    72\n\n\n\n\nAnalysis 2\nSince War was the most common word in game names I decided to look at how many war related games there were. The dataset has a column called category in which the content category of the game is represented. One game can have several categories listed, categories include: fantasy, exploration, adventure, wargame, and many more. I wanted to explore how many games per year are categorized as wargames and if there has been a change in the number of war games released per year. The graphs below explores this question.\n\n\nPlot creation - number of war games published per year\nwar_games &lt;- board_games |&gt; \n  select(name, year_published, category, average_rating) |&gt; \n  group_by(year_published)|&gt; \n  summarize(\n    games_per_year = n(), \n    war_games = sum(str_detect(category, \"(?i)wargame\")), \n    name = name)|&gt; \n  filter(war_games &gt; 0) |&gt; \n  mutate(proportion = war_games/games_per_year)\n\nggplot(war_games, aes(x = year_published, y = war_games)) + \ngeom_point() + \ngeom_line() + \nlabs(\n  title = \"Number of war games published per year from 1955-2016\", \n  x = \"year\", \n  y = \"number of games published\"\n)\n\n\n\n\n\n\n\n\n\n\n\nPlot creation - proportion of war games published per year\nggplot(war_games, aes(x = year_published, y = proportion)) + \ngeom_point() + \ngeom_line() + \nlabs(\n  title = \"Proportion of war games published per year from 1955-2016\", \n  x = \"year\", \n  y = \"proportion of total games\"\n)\n\n\n\n\n\n\n\n\n\nThe first graph shows a sharp increase in the number of war games released between 1970 and 1980 and another sharp increase after 2000. From this graph it would be tempting to say that overall there has been an overall increase in the number of war related game sinse the mid 1900’s. However, it is important to take into account the total number of released games. The second graph shows the proportion of games that are considered war games. In this graph we can see that following a low period in the mid-60s, there was a dramatic increase in proportion from the 1970-1980. This aligns with what the first graph showed. The second graph shows that between 1990 and 2000 the proportion of war games decreased and in 2016 the proportion of war games was relatively the same as in 1965. These graphs demonstrate the importance of looking at proportion instead of just quantity.\n\n\nAnalysis 3\n\n\nTibble of war and average rating\nboard_games |&gt; \n  select(name, year_published, category, average_rating) |&gt;\n  mutate(war = str_extract(category, \"((?&lt;=World War )I+)|(?i)Fantasy.*wargame\")) |&gt; \n  mutate(war = str_sub(war, 1, 7))|&gt;\n  filter(!is.na(war)) |&gt;\n  group_by(war) |&gt; \n  summarize(\n    count = n(), \n    average_rating = sum(average_rating)/n())\n\n\n# A tibble: 3 × 3\n  war     count average_rating\n  &lt;chr&gt;   &lt;int&gt;          &lt;dbl&gt;\n1 Fantasy   139           6.59\n2 I         116           6.91\n3 II        668           6.88\n\n\nThe table above shows how many games were published that were categorized as games about World War I, World War II or Fantasy War. There were almost 6 times as many games made about World War II than World War I and Fantasy War games. Across the three, World War I games have a slightly better average rating but overall they have similar ratings.\n\n\nReferences\nOriginal Source: https://boardgamegeek.com/ Tidy Tuesday Source: https://github.com/rfordatascience/tidytuesday/blob/main/data/2019/2019-03-12/readme.md"
  },
  {
    "objectID": "final_pres.html#project-1",
    "href": "final_pres.html#project-1",
    "title": "Final Presentation",
    "section": "Project 1",
    "text": "Project 1\n\nOverviewDataOriginal Project\n\n\n\nNational Parks Service Data on the 15 most popular National Parks\nData about every species in the park\nAnalyzed species categories (ex: Mammal, Insect, Plant)\n\n\n\n\n\n# A tibble: 6 × 28\n  ParkCode ParkName          CategoryName Order Family TaxonRecordStatus SciName\n  &lt;chr&gt;    &lt;chr&gt;             &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;             &lt;chr&gt;  \n1 ACAD     Acadia National … Mammal       Arti… Cervi… Active            Alces …\n2 ACAD     Acadia National … Mammal       Arti… Cervi… Active            Odocoi…\n3 ACAD     Acadia National … Mammal       Carn… Canid… Active            Canis …\n4 ACAD     Acadia National … Mammal       Carn… Canid… Active            Canis …\n5 ACAD     Acadia National … Mammal       Carn… Canid… Active            Vulpes…\n6 ACAD     Acadia National … Mammal       Carn… Felid… Active            Lynx c…\n# ℹ 21 more variables: CommonNames &lt;chr&gt;, Synonyms &lt;lgl&gt;, ParkAccepted &lt;lgl&gt;,\n#   Sensitive &lt;lgl&gt;, RecordStatus &lt;chr&gt;, Occurrence &lt;chr&gt;,\n#   OccurrenceTags &lt;chr&gt;, Nativeness &lt;chr&gt;, NativenessTags &lt;chr&gt;,\n#   Abundance &lt;chr&gt;, NPSTags &lt;chr&gt;, ParkTags &lt;chr&gt;, References &lt;dbl&gt;,\n#   Observations &lt;dbl&gt;, Vouchers &lt;dbl&gt;, ExternalLinks &lt;lgl&gt;, TEStatus &lt;chr&gt;,\n#   StateStatus &lt;chr&gt;, OzoneSensitiveStatus &lt;chr&gt;, GRank &lt;chr&gt;, SRank &lt;chr&gt;\n\n\n\n\n\nOriginally, explored the species categories in Rocky Mountain National Park.\n\n\nmost_visited_nps_species_data |&gt; \n  filter(ParkCode == \"ROMO\") |&gt; \n  group_by(CategoryName) |&gt; \n  summarize(count = n()) |&gt; \n  filter(count &gt; 50) |&gt; \n  ggplot(aes(x = reorder(CategoryName, -count), y = count, fill = CategoryName)) + \n    geom_col() + \n    theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))+\n    labs(\n      x = \"Species Category\", \n      y = \"Number of species\",\n      title = \"Categories of Species in Rocky Mountain National Park\",\n      fill = \"Category\"\n    )"
  },
  {
    "objectID": "final_pres.html#shiny-updates",
    "href": "final_pres.html#shiny-updates",
    "title": "Final Presentation",
    "section": "Shiny Updates",
    "text": "Shiny Updates\n\nShiny AppUI CodeServer Code\n\n\n\nUsed Shiny to make the database more interactive\nUsing reactive\n\n\n\n\n\nHere is the UI code for the Shiny app:\n\nlibrary(shiny)\nlibrary(tidyverse)\n\n# Define UI\nsidebarLayout(\n  sidebarPanel(\n    selectInput(\n      inputId = \"selected_park\",\n      label = \"Choose a National Park:\",\n      choices = NULL,  # Start with an empty list\n      selected = \"ROMO\"\n    ),\n    radioButtons(\n      inputId = \"plot_type\",\n      label = \"Select plot type:\",\n      choices = c(\"Bar Chart\" = \"bar\", \"Pie Chart\" = \"pie\"),\n      selected = \"bar\"\n    ),\n    selectInput(\n      inputId = \"exclude\",\n      label = \"Exclude Species Categories:\",\n      choices = NULL,  # Start with an empty list\n      multiple = TRUE,\n      selectize = TRUE\n    ),\n    sliderInput(\n      inputId = \"top_n\",\n      label = \"Number of species categories to show:\",\n      min = 1,\n      max = 10,\n      value = 5\n    )\n  ),\n  mainPanel(\n    plotOutput(\"species_plot\")\n  )\n)\n\n\n\nHere is the server code for the Shiny App:\n\nlibrary(shiny)\n# Define Server\nserver &lt;- function(input, output, session) {\n  \n  # Load the data and park names with reactive\n  most_visited_nps_species_data &lt;- reactive({\n    readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-10-08/most_visited_nps_species_data.csv', show_col_types = FALSE)\n  })\n  \n  # Get park choices with reactive\n  park_choices &lt;- reactive({\n    most_visited_nps_species_data() |&gt; \n      select(ParkName, ParkCode) |&gt; \n      distinct() |&gt; \n      arrange(ParkName)\n  })\n  \n  # Update the dropdown for parks\n  observe({\n    updateSelectInput(session, \"selected_park\", choices = setNames(park_choices()$ParkCode, park_choices()$ParkName), selected = \"ROMO\")\n  })\n  \n  # Update the exclude categories \n  observe({\n    updateSelectInput(session, \"exclude\", choices = unique(most_visited_nps_species_data()$CategoryName))\n  })\n  \n  # Filtering and creating the plot\n  output$species_plot &lt;- renderPlot({\n    filtered_data &lt;- most_visited_nps_species_data() |&gt;\n      filter(ParkCode == input$selected_park) |&gt;\n      filter(!CategoryName %in% input$exclude) |&gt;\n      group_by(CategoryName) |&gt;\n      summarize(count = n()) |&gt;\n      arrange(desc(count))|&gt;\n      head(input$top_n)\n    \n    park_name &lt;- park_choices() |&gt;\n      filter(ParkCode == input$selected_park) |&gt;\n      pull(ParkName)\n    \n    if (input$plot_type == \"bar\") {\n      ggplot(filtered_data, aes(x = reorder(CategoryName, -count), y = count, fill = CategoryName)) +\n        geom_col() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +\n        labs(\n          x = \"Species Category\",\n          y = \"Number of Species\",\n          title = paste(\"Bar Graph of Species Categories in\", park_name),\n          fill = \"Category\"\n        )\n    } else if (input$plot_type == \"pie\") {\n      ggplot(filtered_data, aes(x = \"\", y = count, fill = CategoryName)) +\n        geom_bar(width = 1, stat = \"identity\") +\n        coord_polar(\"y\") +\n        theme_void() +\n        labs(\n          title = paste(\"Pie Chart of Species Categories in\", park_name),\n          fill = \"Category\"\n        )\n    }\n  })\n}"
  },
  {
    "objectID": "final_pres.html#thank-you",
    "href": "final_pres.html#thank-you",
    "title": "Final Presentation",
    "section": "Thank you!!",
    "text": "Thank you!!"
  }
]